{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "civil-newsletter",
   "metadata": {},
   "source": [
    "# Meta-learn optimal weight sharing in MLP\n",
    "\n",
    "Here is an idea to find “the optimal weight sharing” in a one linear layer:\n",
    "Let the weights of linear layer be w \\in R^n. Let v \\in R^k be the vector of all unique weights (k unique weights).\n",
    "during training we calculate w with w=Av, essentially taking linear combination of v_1,…, v_k.\n",
    "However we soft enforce (with a loss function) that the rows of A have low entropy (pick a single unique weight) and/or rows of A prefer v_1, v_2, etc. more than v_1000, v_1001, etc… (to use as few unique weights as possible)\n",
    "We train over the matrix A and the unique weights v.\n",
    "The resulting weight vector w will be in some sense the optimal weight sharing version of w.\n",
    "We can analyze which weights are learned to be shared by looking at rows of A.\n",
    "My hope is that it can recover CNN weight sharing or transformer weight sharing or some other human interpretable weight sharing that may give insight into how to engineer inductive biases in the future.\n",
    "Maybe it finds optimal inductive bias for images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compound-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-delight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stylish-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mnist.MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-discrimination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "given-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(28*28, 500)\n",
    "\n",
    "v = torch.randn(500)\n",
    "# w.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "together-manufacturer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ap = A.softmax(dim=-1)\n",
    "w = Ap@v\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elect-titanium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7182)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributions.Categorical(probs=Ap).entropy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "impossible-proceeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81840\n",
      "8153200\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_sizes=[100], nonlin=torch.relu):\n",
    "        super().__init__()\n",
    "        hidden_sizes = [28*28] + hidden_sizes + [10]\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        \n",
    "        self.weights = [torch.randn(o, i+1)*0.01 for o, i in zip(hidden_sizes[1:], hidden_sizes[:-1])]\n",
    "        self.weights = nn.ParameterList([nn.Parameter(w) for w in self.weights])\n",
    "        \n",
    "#         for w in self.weights:\n",
    "#             print(w.shape)\n",
    "            \n",
    "        self.nonlin = nonlin\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(len(x), -1)\n",
    "        for wb in self.weights:\n",
    "            w, b = wb[:, :-1], wb[:, -1]\n",
    "            x = x@w.T+b\n",
    "            \n",
    "            x = self.nonlin(x)\n",
    "#             x = x+y if x.shape==y.shape else y\n",
    "        return x\n",
    "\n",
    "class SharedNet(nn.Module):\n",
    "    def __init__(self, hidden_sizes=[100], ks=[10, 10], nonlin=torch.relu):\n",
    "        super().__init__()\n",
    "        hidden_sizes = [28*28] + hidden_sizes + [10]\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        \n",
    "        self.As = [torch.randn(o*(i+1), k)*0.0001 for o, i, k in zip(hidden_sizes[1:], hidden_sizes[:-1], ks)]\n",
    "        self.vs = [torch.randn(k)*0.01 for k in ks]\n",
    "        \n",
    "        self.As = nn.ParameterList([nn.Parameter(A) for A in self.As])\n",
    "        self.vs = nn.ParameterList([nn.Parameter(v) for v in self.vs])\n",
    "        \n",
    "#         for w in self.weights:\n",
    "#             print(w.shape)\n",
    "            \n",
    "        self.nonlin = nonlin\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(len(x), -1)\n",
    "        for A, v, i, o in zip(self.As, self.vs, self.hidden_sizes[:-1], self.hidden_sizes[1:]):\n",
    "#             A = A.softmax(dim=-1)\n",
    "            wb = A@v\n",
    "            wb = wb.reshape(o, i+1)\n",
    "            \n",
    "            w, b = wb[:, :-1], wb[:, -1]\n",
    "            x = x@w.T+b\n",
    "            \n",
    "            x = self.nonlin(x)\n",
    "#             x = x+y if x.shape==y.shape else y\n",
    "        return x\n",
    "    \n",
    "    \n",
    "net = Net([100,30])\n",
    "print(np.sum([p.numel() for p in net.parameters()]))\n",
    "net = SharedNet([100,30], [100, 100])\n",
    "print(np.sum([p.numel() for p in net.parameters()]))\n",
    "\n",
    "# net(torch.randn(100, 28*28)).shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "atomic-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "metropolitan-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ds_stats(net, loader):\n",
    "    losses = []\n",
    "    accs = []\n",
    "    for batch_idx, (X_batch, Y_batch) in enumerate(loader):\n",
    "        Y_batch_pred = net(X_batch)\n",
    "        loss = loss_function(Y_batch_pred, Y_batch)\n",
    "        losses.append(loss.item())\n",
    "        Y_batch_pred_idx = Y_batch_pred.argmax(dim=-1)\n",
    "        acc = (Y_batch_pred_idx==Y_batch).sum().item()/len(Y_batch)\n",
    "        accs.append(acc)\n",
    "    return np.average(losses), np.average(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "crude-banner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.401261627674103, 0.0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_ds_stats(net, m.loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "amended-testament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2228d0d766fd437baca4a11f7f76025b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67fdf13f18a4294a5dd01285d98fc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.243442952632904, 0.14216666666666666)\n",
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7825539f61a84a359dfaa60ca45e0ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.2196162343025208, 0.29525)\n",
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a61bed908bb4f23977d931569106c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4878960847854614, 0.5845833333333333)\n",
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc8b92a4b0c4c149cb6bfcd57fae3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.072504237294197, 0.7344166666666666)\n",
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90310e4d05c445dfaba105903af38ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9305860996246338, 0.7659166666666667)\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch_idx in tqdm(range(5)):\n",
    "    print(epoch_idx)\n",
    "    for batch_idx, (X_batch, Y_batch) in tqdm(enumerate(m.loader_test), total=len(m.loader_test)):\n",
    "#         X_batch, Y_batch = X, Y\n",
    "        Y_batch_pred = net(X_batch)\n",
    "        loss = loss_function(Y_batch_pred, Y_batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "#     plt.plot(losses);plt.show() \n",
    "    print(calc_ds_stats(net, m.loader_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aerial-recruitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9229292720556259, 0.7689166666666667)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_ds_stats(net, m.loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-opening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-sarah",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-cylinder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-legend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-hollywood",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
